### 2025-12-01-1854 – Snapshots pinned to detection frame

- **Owner**: GPT-5 via Codex CLI (bug fix)
- **Agents affected**: TaskOrchestrator, perception tracker, docs
- **Git commit(s)**: Based on b0fe9d08ba6bb15e921759dcefca9755323da831
- **Context**: Snapshots were writing detections from the long-lived registry and using a fresh camera frame, so out-of-view objects stayed in `detections.json` and bounding boxes drifted after camera motion.
- **Actions**:
  - Cached the latest detection bundle (color/depth/intrinsics + objects) in `ObjectTracker` with locking for snapshot reuse.
  - Built `save_snapshot(...)` from that bundle (including detection timestamp) and limited detections to the most recent pass instead of the full registry.
  - Updated orchestrator docs to call out bundle-backed snapshots and detection-only payloads.
- **Result**: Snapshots now serialize only on-frame objects from the last detection and keep bounding boxes aligned with the stored image even when the camera moves between detection and persistence.
- **References**: src/perception/object_tracker.py, src/planning/task_orchestrator.py, agents/design/architecture.md, agents/design/orchestrator_observation_snapshot_plan.md, docs/ORCHESTRATOR.md

### 2025-12-01-1744 – Cookbook-style detection output + lean re-ID context

- **Owner**: GPT-5 via Codex CLI (perception prompt tuning)
- **Agents affected**: Perception tracker, perception prompts, docs
- **Git commit(s)**: Based on b0fe9d08ba6bb15e921759dcefca9755323da831
- **Context**: Gemini detection occasionally ignored ID reuse and emitted non-standard box formats; needed to match the cookbook JSON bbox pattern and trim redundant prior frames so re-ID stays focused.
- **Actions**:
  - Updated the detection current-frame prompt to request only a JSON array of `{box_2d, label}` entries (integers, 0–1000, max 25), reusing existing IDs in `label` when visible.
  - Added a detection response parser that consumes the JSON array (with legacy fallback) and maps labels/bboxes into the tracker’s callback flow.
  - Selected the minimal set of recent observations (latest sighting per object) before attaching prior frames to the detection request.
  - Synced perception/prompt docs with the new detection output contract.
- **Result**: Detection prompts now align with Gemini cookbook guidance, parsed responses are structured, and re-ID context avoids redundant frames.
- **References**: config/prompts_config.yaml, src/perception/object_tracker.py, agents/design/prompts_configuration.md, docs/perception.md

### 2025-12-01-1718 – Clarified detection prompt separators

- **Owner**: GPT-5 via Codex CLI (prompt clarity)
- **Agents affected**: Perception prompts, docs
- **Git commit(s)**: Based on b0fe9d08ba6bb15e921759dcefca9755323da831
- **Context**: Requested clearer separation between prior detections/images and the current frame so the model only runs detection on the new image while reusing previous IDs.
- **Actions**:
  - Added explicit separator lines in the detection streaming prompt marking prior IDs/images vs. the current frame, instructing detection only on the first attached image.
  - Updated perception prompt documentation to describe the new separators and reference-only use of prior frames.
- **Result**: Detection prompt now visually isolates prior context from the current frame, reducing chances of running detection on reference images; docs remain synchronized.
- **References**: config/prompts_config.yaml, agents/design/prompts_configuration.md, docs/perception.md

### 2025-12-01-1723 – Two-turn detection prompt delivery

- **Owner**: GPT-5 via Codex CLI (prompt clarity)
- **Agents affected**: Perception tracker, perception docs
- **Git commit(s)**: Based on b0fe9d08ba6bb15e921759dcefca9755323da831
- **Context**: Gemini occasionally anchored detections to prior reference images; need to split the prompt so prior context and current frame arrive as separate turns.
- **Actions**:
  - Added two-turn assembly for detection prompts: turn 1 sends prior IDs/images only, turn 2 sends the current frame plus detection instructions.
  - Wired `_detect_object_names_streaming` to stream content parts with prior image parts + prior prompt, then current frame + current instructions; updated prompt docs to note the two-turn packaging.
- **Result**: Detection is now anchored to the current image while still leveraging prior context for ID reuse.
- **References**: src/perception/object_tracker.py, agents/design/prompts_configuration.md, docs/perception.md

### 2025-12-01-1725 – YAML split into prior/current detection turns

- **Owner**: GPT-5 via Codex CLI (prompt clarity)
- **Agents affected**: Perception prompts, tracker, docs
- **Git commit(s)**: Based on b0fe9d08ba6bb15e921759dcefca9755323da831
- **Context**: Follow-up to two-turn delivery—remove in-prompt split markers and encode the two turns directly in YAML for clarity and robustness.
- **Actions**:
  - Restructured `config/prompts_config.yaml` to define `detection.streaming.prior` and `detection.streaming.current` templates (prior turn: IDs + prior images, no detection; current turn: detection instructions on current frame).
  - Updated tracker formatting to use the two templates without string splitting; ensured fallback defaults keep turn semantics.
  - Refreshed perception prompt docs to describe the prior/current templates.
- **Result**: Two-turn detection packaging now lives in YAML, reducing reliance on in-string split tokens while keeping re-ID context separate from current-frame detection.
- **References**: config/prompts_config.yaml, src/perception/object_tracker.py, agents/design/prompts_configuration.md, docs/perception.md

### 2025-12-01-1548 – Perception prompt JSON migration and streaming-only schema cleanup

- **Owner**: GPT-5 via Codex CLI (prompt/schema sync)
- **Agents affected**: Perception prompts, tracker, docs
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: Perception prompts moved from YAML to JSON with structured outputs; detection now runs streaming-only but still needs schema guidance for parity.
- **Actions**:
  - Replaced `config/prompts_config.yaml` with `config/prompts_config.json`, carrying detection/analysis/interaction prompts plus structured schemas.
  - Dropped `detection.batch` and removed batch fallback handling from `_detect_object_names_streaming`; detection is streaming-only.
  - Added titles/descriptions to `response_schema` entries (detection/analysis/interaction) and removed response templates in favor of schema guidance.
  - Updated perception/prompt docs and playbooks to reflect the JSON config, streaming-only detection, and schema-driven structured outputs.
- **Result**: Perception prompts align with the decomposer’s JSON+schema pattern; streaming detection remains the only path, with schemas retained for structured generation guidance.
- **References**: config/prompts_config.json, src/perception/object_tracker.py, docs/perception.md, agents/design/prompts_configuration.md, agents/operations/playbook.md

### 2025-12-01-1553 – Tightened affordance schema to enforce strings

- **Owner**: GPT-5 via Codex CLI (prompt/schema sync)
- **Agents affected**: Perception prompts
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: LLM responses were emitting affordances as dicts, causing parsing to fail when converting to a set.
- **Actions**: Updated `analysis.response_schema.affordances` in `config/prompts_config.json` to require string items with titles/descriptions and `uniqueItems: true`.
- **Result**: Schema now more explicitly demands string affordance labels, reducing chances of dict-shaped affordance outputs.
- **References**: config/prompts_config.json

### 2025-12-01-1557 – Affordance parsing guardrail

- **Owner**: GPT-5 via Codex CLI (bug fix)
- **Agents affected**: Perception tracker
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: LLM still returned dict-shaped affordances, causing `TypeError: unhashable type: 'dict'` when converting to a set.
- **Actions**: Added affordance normalization in `src/perception/object_tracker.py` to coerce dict keys/iterables into strings and ignore non-string items before building the set.
- **Result**: Affordance parsing no longer crashes on dict-shaped outputs; detection/analysis can proceed.
- **References**: src/perception/object_tracker.py

### 2025-12-01-1559 – Reverted to YAML prompts and dropped structured outputs

- **Owner**: GPT-5 via Codex CLI (rollback)
- **Agents affected**: Perception prompts, tracker, docs
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: JSON+schema attempt caused parsing instability; reverting to the prior YAML prompt config with streaming-only detection and no structured outputs.
- **Actions**:
  - Restored `config/prompts_config.yaml` (original prompt text) and removed `config/prompts_config.json`.
  - Updated `ObjectTracker` to load YAML and removed structured-response config wiring; kept streaming-only detection without batch fallback.
  - Refreshed docs/playbooks to point back to the YAML prompt config and drop structured-output notes.
- **Result**: Perception returns to the stable YAML prompt setup with streaming detection and text-driven responses.
- **References**: config/prompts_config.yaml, src/perception/object_tracker.py, docs/perception.md, agents/design/prompts_configuration.md, agents/operations/playbook.md, AGENTS.md

### 2025-12-01-1504 – Re-ID prompting and logger plumbing

- **Owner**: GPT-5 via Codex CLI (perception tuning)
- **Agents affected**: Perception, orchestrator
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: Continuous detection was re-minting IDs and emitting print-based logs; needed logger injection and prior-frame context for re-identification.
- **Actions**:
  - Added logger injection to `ObjectTracker`/`ContinuousObjectTracker` and propagated the orchestrator logger; replaced prints with structured logs.
  - Cached recent observations (images + per-object positions) and attach them to detection prompts with `existing_objects_section` + `prior_images_section` plus corresponding image parts.
  - Updated detection prompts/doc to describe prior image sections for ID reuse.
- **Result**: Tracker logs now flow through the orchestrator logger, and detection prompts carry recent visual context to keep object IDs stable across cycles.
- **References**: src/perception/object_tracker.py, config/prompts_config.yaml, agents/design/prompts_configuration.md, src/planning/task_orchestrator.py

### 2025-12-01-1444 – Added re-identification context to detection

- **Owner**: GPT-5 via Codex CLI (prompt tuning)
- **Agents affected**: Perception prompts, object tracker
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: Continuous detection was minting new object IDs every cycle; updated prompts + tracker to reuse existing registry entries when objects stay visible.
- **Actions**:
  - Injected registry context into detection prompts (`existing_objects_section`) and instructed Gemini to reuse IDs when objects persist.
  - Formatted detection prompts per mode via `_format_detection_prompt`, passing prior bboxes/types into `_detect_object_names_streaming`.
  - Reused IDs in `_analyze_single_object` when detection returns an existing name; documented the behavior in perception/prompt docs.
- **Result**: Detection cycles now encourage re-identification instead of creating duplicate objects; docs reflect the new prompt contract.
- **References**: src/perception/object_tracker.py, config/prompts_config.yaml, docs/perception.md, agents/design/prompts_configuration.md

### 2025-12-01-1354 – Flattened continuous tracker wrapper

- **Owner**: GPT-5 via Codex CLI (refactoring)
- **Agents affected**: Perception, orchestrator, demos, docs
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: Simplified `ContinuousObjectTracker` per request by merging it into the core tracker module and dropping scene-change embedding logic while keeping the async update loop.
- **Actions**:
  - Moved `ContinuousObjectTracker`/`TrackingStats` into `src/perception/object_tracker.py` as a subclass with an always-true `should_detect` hook; removed the old module.
  - Updated orchestrator/config and demos to call tracker methods directly (no nested `.tracker`) and align frame providers with `(color, depth, intrinsics)`.
  - Refreshed perception/orchestrator documentation and agent playbooks to remove scene-change tuning references.
- **Result**: Leaner continuous tracking code paths with fewer imports/LOC, consistent registry access, and docs reflecting the simplified design.
- **References**: src/perception/object_tracker.py, config/orchestrator_config.py, src/planning/task_orchestrator.py, examples/continuous_pddl_simple_demo.py, examples/pddl_predicate_tracking_demo.py, docs/perception.md, agents/design/architecture.md, agents/operations/playbook.md, agents/design/prompts_configuration.md
