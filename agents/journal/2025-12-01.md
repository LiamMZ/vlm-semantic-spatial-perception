### 2025-12-01-1548 – Perception prompt JSON migration and streaming-only schema cleanup

- **Owner**: GPT-5 via Codex CLI (prompt/schema sync)
- **Agents affected**: Perception prompts, tracker, docs
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: Perception prompts moved from YAML to JSON with structured outputs; detection now runs streaming-only but still needs schema guidance for parity.
- **Actions**:
  - Replaced `config/prompts_config.yaml` with `config/prompts_config.json`, carrying detection/analysis/interaction prompts plus structured schemas.
  - Dropped `detection.batch` and removed batch fallback handling from `_detect_object_names_streaming`; detection is streaming-only.
  - Added titles/descriptions to `response_schema` entries (detection/analysis/interaction) and removed response templates in favor of schema guidance.
  - Updated perception/prompt docs and playbooks to reflect the JSON config, streaming-only detection, and schema-driven structured outputs.
- **Result**: Perception prompts align with the decomposer’s JSON+schema pattern; streaming detection remains the only path, with schemas retained for structured generation guidance.
- **References**: config/prompts_config.json, src/perception/object_tracker.py, docs/perception.md, agents/design/prompts_configuration.md, agents/operations/playbook.md

### 2025-12-01-1553 – Tightened affordance schema to enforce strings

- **Owner**: GPT-5 via Codex CLI (prompt/schema sync)
- **Agents affected**: Perception prompts
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: LLM responses were emitting affordances as dicts, causing parsing to fail when converting to a set.
- **Actions**: Updated `analysis.response_schema.affordances` in `config/prompts_config.json` to require string items with titles/descriptions and `uniqueItems: true`.
- **Result**: Schema now more explicitly demands string affordance labels, reducing chances of dict-shaped affordance outputs.
- **References**: config/prompts_config.json

### 2025-12-01-1557 – Affordance parsing guardrail

- **Owner**: GPT-5 via Codex CLI (bug fix)
- **Agents affected**: Perception tracker
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: LLM still returned dict-shaped affordances, causing `TypeError: unhashable type: 'dict'` when converting to a set.
- **Actions**: Added affordance normalization in `src/perception/object_tracker.py` to coerce dict keys/iterables into strings and ignore non-string items before building the set.
- **Result**: Affordance parsing no longer crashes on dict-shaped outputs; detection/analysis can proceed.
- **References**: src/perception/object_tracker.py

### 2025-12-01-1559 – Reverted to YAML prompts and dropped structured outputs

- **Owner**: GPT-5 via Codex CLI (rollback)
- **Agents affected**: Perception prompts, tracker, docs
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: JSON+schema attempt caused parsing instability; reverting to the prior YAML prompt config with streaming-only detection and no structured outputs.
- **Actions**:
  - Restored `config/prompts_config.yaml` (original prompt text) and removed `config/prompts_config.json`.
  - Updated `ObjectTracker` to load YAML and removed structured-response config wiring; kept streaming-only detection without batch fallback.
  - Refreshed docs/playbooks to point back to the YAML prompt config and drop structured-output notes.
- **Result**: Perception returns to the stable YAML prompt setup with streaming detection and text-driven responses.
- **References**: config/prompts_config.yaml, src/perception/object_tracker.py, docs/perception.md, agents/design/prompts_configuration.md, agents/operations/playbook.md, AGENTS.md

### 2025-12-01-1504 – Re-ID prompting and logger plumbing

- **Owner**: GPT-5 via Codex CLI (perception tuning)
- **Agents affected**: Perception, orchestrator
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: Continuous detection was re-minting IDs and emitting print-based logs; needed logger injection and prior-frame context for re-identification.
- **Actions**:
  - Added logger injection to `ObjectTracker`/`ContinuousObjectTracker` and propagated the orchestrator logger; replaced prints with structured logs.
  - Cached recent observations (images + per-object positions) and attach them to detection prompts with `existing_objects_section` + `prior_images_section` plus corresponding image parts.
  - Updated detection prompts/doc to describe prior image sections for ID reuse.
- **Result**: Tracker logs now flow through the orchestrator logger, and detection prompts carry recent visual context to keep object IDs stable across cycles.
- **References**: src/perception/object_tracker.py, config/prompts_config.yaml, agents/design/prompts_configuration.md, src/planning/task_orchestrator.py

### 2025-12-01-1444 – Added re-identification context to detection

- **Owner**: GPT-5 via Codex CLI (prompt tuning)
- **Agents affected**: Perception prompts, object tracker
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: Continuous detection was minting new object IDs every cycle; updated prompts + tracker to reuse existing registry entries when objects stay visible.
- **Actions**:
  - Injected registry context into detection prompts (`existing_objects_section`) and instructed Gemini to reuse IDs when objects persist.
  - Formatted detection prompts per mode via `_format_detection_prompt`, passing prior bboxes/types into `_detect_object_names_streaming`.
  - Reused IDs in `_analyze_single_object` when detection returns an existing name; documented the behavior in perception/prompt docs.
- **Result**: Detection cycles now encourage re-identification instead of creating duplicate objects; docs reflect the new prompt contract.
- **References**: src/perception/object_tracker.py, config/prompts_config.yaml, docs/perception.md, agents/design/prompts_configuration.md

### 2025-12-01-1354 – Flattened continuous tracker wrapper

- **Owner**: GPT-5 via Codex CLI (refactoring)
- **Agents affected**: Perception, orchestrator, demos, docs
- **Git commit(s)**: Based on fd01602ac485370d90e56f2c999d87e6c696d483
- **Context**: Simplified `ContinuousObjectTracker` per request by merging it into the core tracker module and dropping scene-change embedding logic while keeping the async update loop.
- **Actions**:
  - Moved `ContinuousObjectTracker`/`TrackingStats` into `src/perception/object_tracker.py` as a subclass with an always-true `should_detect` hook; removed the old module.
  - Updated orchestrator/config and demos to call tracker methods directly (no nested `.tracker`) and align frame providers with `(color, depth, intrinsics)`.
  - Refreshed perception/orchestrator documentation and agent playbooks to remove scene-change tuning references.
- **Result**: Leaner continuous tracking code paths with fewer imports/LOC, consistent registry access, and docs reflecting the simplified design.
- **References**: src/perception/object_tracker.py, config/orchestrator_config.py, src/planning/task_orchestrator.py, examples/continuous_pddl_simple_demo.py, examples/pddl_predicate_tracking_demo.py, docs/perception.md, agents/design/architecture.md, agents/operations/playbook.md, agents/design/prompts_configuration.md
