### 2025-12-02-1642 – Collapse task analyzer onto single analysis template

- **Owner**: AI Agent (prompt maintenance)
- **Agents affected**: LLMTaskAnalyzer, docs/planning
- **Git commit(s)**: Based on 8ebbf948e736f81fb58c6f3dd10e8e055835edf5
- **Context**: Align the task analyzer so every run—initial or observation-backed—renders the same analysis instructions and remove the redundant `initial_prompt` definition from the prompt pack.
- **Actions**:
  - Replaced the bespoke `initial_prompt` text with the analysis template rendered for zero observations, adding placeholder descriptions for missing objects/relationships.
  - Deleted `initial_prompt` from `config/llm_task_analyzer_prompts.yaml` to keep `analysis_prompt` as the sole authoritative template.
  - Updated `LLMTaskAnalyzer` to always render that template while injecting placeholder summaries whenever perception returns no objects or relationships.
  - Refreshed `docs/planning.md` to document the single-template behavior.
- **Result**: Initial and observation-backed analyses now share identical formatting, and the YAML no longer duplicates instructions while still informing the LLM when perception data is absent.
- **References**: `config/llm_task_analyzer_prompts.yaml`, `src/planning/llm_task_analyzer.py`, `docs/planning.md`

### 2025-12-02-1455 – Prompt config alignment across perception + planning

- **Owner**: AI Agent (config maintenance)
- **Agents affected**: ObjectTracker, LLMTaskAnalyzer, docs/perception, docs/planning, agent ops docs
- **Git commit(s)**: Based on ed3cdbf027bf1535738633be1e60567a21ea7d34
- **Context**: Align the perception prompt pack name with its scope (ObjectTracker-only), externalize the LLM task analyzer prompts into YAML like the rest of the stack, and prune unused config files.
- **Actions**:
  - Renamed `config/prompts_config.yaml` to `config/object_tracker_prompts.yaml` via `git mv`.
  - Updated `ObjectTracker.DEFAULT_PROMPTS_CONFIG` and related doc strings to point to the new path.
  - Added `config/llm_task_analyzer_prompts.yaml`, wired `LLMTaskAnalyzer` to load it (with override support), and introduced shared template rendering helpers.
  - Compactified the LLM task analyzer prompts so only dynamic values (task text, robot description, JSON summaries of objects/relationships) are templated; static instructions now live entirely in the YAML, which now owns the optional robot capability description (init arg removed).
  - Externalized the domain-refinement prompt to `config/pddl_domain_maintainer_prompts.yaml`, added a prompts loader to `PDDLDomainMaintainer`, and now render the refinement template with only dynamic sections (error text, goal objects, robot context, domain/problem snippets).
  - Deleted unused `config/gemini.yaml`, `config/gemini_config.yaml`, and `config/perception_config.yaml`.
  - Refreshed planning + agent documentation (`docs/planning.md`, `docs/README.md`, `agents/design/architecture.md`, `agents/operations/playbook.md`, `AGENTS.md`) to reference the new configs and upkeep rules.
- **Result**: Both perception and planning layers now load prompts from explicit YAML packs, and stale configs were removed to avoid drift.
- **References**: `config/object_tracker_prompts.yaml`, `config/llm_task_analyzer_prompts.yaml`, `config/pddl_domain_maintainer_prompts.yaml`, `src/perception/object_tracker.py`, `src/planning/llm_task_analyzer.py`, `src/planning/pddl_domain_maintainer.py`, `docs/perception.md`, `docs/planning.md`, `docs/README.md`, `agents/design/prompts_configuration.md`, `agents/design/architecture.md`, `agents/operations/playbook.md`, `AGENTS.md`

